# 词汇表大小修复说明

## 问题描述
训练后的模型无法加载，报错：
```
size mismatch for base_model.model.model.embed_tokens.weight: 
copying a param with shape torch.Size([151669, 1024]) from checkpoint, 
the shape in current model is torch.Size([151936, 1024])
```

## 解决方案
我已经修改了以下文件以确保训练时不改变词汇表大小：

### 1. train.py 修改
- 在 `setup_model()` 方法中移除了 `model.resize_token_embeddings()` 调用
- 添加了词汇表大小检查，但不进行调整
- 确保使用 unk_token 处理未知词汇

### 2. model_utils.py 修改  
- 在 `load_tokenizer()` 方法中添加了 unk_token 设置逻辑
- 自动检测并设置合适的 unk_token（<unk>、[UNK]等）
- 添加详细的tokenizer配置日志

### 3. data_processor.py 修改
- 在tokenization过程中确保正确处理未知词汇
- 添加unk_token使用统计

### 4. app.py 修改
- 更新了训练流程，确保Web界面也使用固定词汇表大小

## 使用方法

### 1. 重新训练模型
```bash
python train.py
```

### 2. 通过Web界面训练
```bash
python start_web.py
# 访问 http://127.0.0.1:8000 进行训练
```

### 3. 推理测试
```bash
python inference.py
```

## 关键改进

1. **固定词汇表大小**: 训练时不调整模型的embedding层大小
2. **UNK处理**: 未知词汇自动映射到unk_token
3. **兼容性**: 确保训练和推理时使用相同的词汇表
4. **日志增强**: 详细记录词汇表配置信息

## 注意事项

- 如果已有旧的训练输出，建议删除 `./outputs/` 目录重新训练
- 确保数据集中的特殊字符能被tokenizer正确处理
- 训练完成后，推理将自动使用正确的tokenizer配置

这样修改后，模型训练和推理都将使用固定的词汇表大小，避免了尺寸不匹配的问题。